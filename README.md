
# Human Age, Gender and Ethnicity Prediction using Machine Learning Algorithms

### Abstract

One of the key components in identifying a person is their face. Science is still conducting research to classify organisms based on the many characteristics of the human body and face. Human faces are primarily categorised according to the age, gender, ethnicity, and expression of the individual. These classifications can be utilised successfully in a variety of contexts, such as business and government. It is frequently used to give kids access to age-appropriate content. In this study, the best machine learning model was chosen after comparing multiple models to improve age, gender, and ethnicity prediction. Therefore, face recognition and other tasks requiring a variety of skills have significantly improved. As hyperparameters are crucial for determining the best deep learning or machine learning model, the goal is to select the best model by incorporating hyperparameter optimization and using them for precise real-time prediction.
Keywords – Age, Gender and Ethnicity prediction, Machine Learning, Deep learning, Hyperparameter optimization

### 1.	Introduction

When communicating amongst people, human faces convey a lot of nonverbal information. The faces of individuals can reveal a variety of characteristics, including age, gender, expression, and ethnicity. Both human-to-human and human-computer interactions can benefit from these qualities. The facial characteristics are often assessed separately and independently from one another given a face image. (Guodong and Wvu) . 
	Three processes make up the overall flow of face recognition: capturing face photos using a camera with visible or near-infrared illumination, extracting features from face images, and determining how similar the features are to one another. The benefit of face recognition is that it has a simpler image acquisition process than other biometric recognition technologies like iris and fingerprint recognition because it doesn't need specialised equipment to take pictures of people's faces. Face recognition has the drawback of having low recognition accuracy because face images are drastically altered by changes in head posture, expression, ageing, etc. (Ito et al., Nov 2018) . Machine learning methodologies are utilized for classification tasks to good effect. Four major approaches for machine learning algorithms — K-Nearest Neighbour (KNN), Convolutional Neural Nertwork (CNN), Naive Bayes, and Region-based Convolutional Neural Network (RCNN)—are primarily used among them. Age, gender, and ethnicity can all be predicted using one of these four methods. Frequently, grid searches or manual methods of hyperparameter tuning are used. 
	Recent studies have revealed that automatic optimization strategies can speed up this optimization process and identify hyperparameter settings that produce superior models. (Wistuba, Schilling and Schmidt-Thieme, Oct 2015)   According to this study, a more precise prediction model can be produced by combining a powerful machine learning algorithm with hyperparameter optimization. Our goal is to create a system that can accurately anticipate a person's age, gender, and ethnicity without jeopardising his or her security or evading any other security measures. Such effective techniques are beneficial in many ways when carrying out various tasks. Building a model that can properly estimate age, gender, and ethnicity is our key objective. It also seeks to be used to age-specific content access restrictions, where the system might determine a person's age, gender, and race and decide whether to allow or deny access depending on those characteristics. (Ito et al., Nov 2018)

### 2.	Literature Review

The literature review on age, gender, and ethnicity identification using various methods and algorithms is described in this part. Ultimately, the classification of age, gender and ethnicity originates from the advanced technology of the process of face detection. A face detection and recognition programme are a piece of software that helps identify people in videos or photos by looking at their faces. The older research on face detection may be found in technical journals, at least for psychoanalytic theory in the 1950s and 1960s. Experiments on Darwin's instincts for facial expression are some of the earliest discoveries. Facial recognition is rapid and accurate with Intel's OpenCV open-source software platform.
	Human face pictures reveal a variety of information, including nationality, age, and gender. By automatically detecting faces, recognising gestures and faces, and determining age, gender, and ethnicity, computer vision and pattern recognition in the field of computer vision provide an ideal role in humans. So, it is important to make sure users and consumers are aware if an application incorporates facial recognition technologies. By doing this, you can help others learn about these technologies. It also gives folks who come to or utilise your facilities or technology the option to determine if they want to keep doing so. 

2.1.	Face Detection

(Khan et al., Oct 2019a)  describes Popular biometrics research topics include face detection and image or video recognition. A fascinating field and a quickly escalating problem exist in real-time face recognition. Programming is simple to use due to Intel's open-source Computer-View library. This offers sophisticated features including several ready-to-use artificial intelligence approaches, including image retrieval, facial tracking, image recognition, and others (AI). It is a model of learning that utilizes computers that builds a cascade function out of numerous both positive and negative expressions. This is then utilised to find items. computing "features" recognised by the hair cascades by "integral image" techniques.
 (Abirami, Subashini and Mahavaishnavi, 2020) proposed the video from the camera may be captured and transformed to picture frames using OpenCV's incredibly straightforward user interface. It used to be common practise to use the pre-trained haar cascade model for face identification, but currently researchers are turning to OpenCV and a deep neural face image detection method based that has been taught model for faster and additional accurate face image detection. In general, Haar cascade Classifier and LBP Cascade Classifier are the two main methods used by OpenCV to locate faces. The Haar classifier is utilised in this study since it is slower than LBP but more accurate.
 
2.2.	Feature Extraction

(Opencv et al., 2021a)  described that There are three fundamental processes in face recognition: face detection, face recognition, and face extraction. In order to locate the face, any system must first capture the image and thereafter manage and record the crucial elements. It maintains records of several features, including skin tone and colour, for the purpose of identifying the taken image. Regions of the face, differences in the anatomy of the face, and formatted and styled face cuts and angles can all be considered facial characteristics. Grabbers of camera characteristics are also used in face extraction. The different areas of the image that are extremely black or extremely brilliant are removed from the image at this stage. Examples of these are the region surrounding the eyes, the region around the nose, or the region below the lips. The most pertinent region that is covered by skin is obtained by removing these areas, and accurate detection is then possible. 
(Srinivas et al., May 2017)  is explained Each of the sub-networks learns features individually, then they are combined and delivered to a layer that is fully connected utilises the cost function as the square difference and may be considered to be a linear regressor. The sub-networks are made up of a locally connected layer, a max-pooling layer, and a convolutional layer. Additionally, that use a unique function lost for determining ethnicity, gender, and age to train the network to learn while performing several tasks. They test the effectiveness of the suggested method using the MORPH 2 dataset, showing a decreased age estimation error rate compared to employing biologically inspired characteristics. 

2.3.	Classification

 (Mahapatra et al., 2021) presented a comprehensive study on several methods and settings for estimating age and gender. The study's framework specifically is a recently discovered common framework: People's facial features may nearly instantly reveal a person's gender to humans. Although automating the same task is challenging, incredible progress has been achieved in automatically predicting facial photos over the previous ten years. The project recognises or determines the gender based on the provided facial photos. The initiative was motivated by robbery, fraud, child molestation, lack of security, and criminal identification. 
 	(Levi and Hassncer, Jun 2015a) provide an innovative method for employing a CNN to classify gender in real-time in this research. These are the primary takeaways from this study. For real-time face-based gender classification, a 4-layer CNN is first proposed. Comparing the network architecture to previous approaches, we find that it has a lower design complexity because there are fewer layers, neurons, trainable parameters, and connections.  (LIEW et al., 2016)  In this study, a gap between automatic facial recognition and gender and age estimate methods is attempted to be filled. To achieve this, we follow the excellent example offered by existing technology for facial recognition. Techniques that have been released recently show that CNN can also be utilised to significantly improve facial recognition systems. 
 	(Taunk et al., May 2019a)  provides various categorization criteria are applied to determine the categorization to which the unlabelled data belongs. KNN is most frequently used as a classifier. It is used to classify data in a specific area based on local or adjacent training samples. This method is used because of its quick analysis and simplicity. It uses the Euclidean distance to locate its nearest neighbours when working with continuous data. The classification for a new sample is selected by the majority of the neighbouring data, and the K nearest neighbours are calculated. Although this classifier is simple, the value of "K" is essential for locating the unlabelled data.
 (Phuiig et al.) proposes a Bayesian classifier is used to first find skin patches in the colour input image. Eye areas are distinguished by their colour characteristic within each skin region. Two face candidates are created for each detected eye pair using a geometric face model that specifies the face region border in terms of the locations of the two eyes. A number of heuristics about the face were preliminary verified against all face candidates. The remaining candidates are turned so that their eyes are horizontal, and they are standing straight. For the classification of faces from nonfaces, a single naive Bayes classifier may be used. However, we believe that using an ensemble of numerous classifiers that also are derived from various feature extraction techniques will improve classification. As a result, we test this theory by evaluating the effectiveness of a grouping of four distinct classifiers.
 (Girshick, Dec 2015) Explained an input image and several regions of concern (RoIs) are fed into a fully convolutional network. Before mapping each RoI to a feature vector, completely connected layers pool each RoI into a corrected feature map (FCs). The 2 output arrays of the network for each RoI are the per-class bounding-box regress offsets and softmax probabilities. From start to finish, the architecture is trained using a multi-task loss. The h w RoI window is subdivided into a H w matrix of sub-windows that really are roughly h/H w/W in size to enhance the pooling of the data in each sub-window into to the accompanying output grid cell.

2.4.	Hyperparameter Optimization

 (Dong et al., 2021) Investigate the most effective and dynamic selection of hyperparameters for visual object tracking, abbreviated tracking throughout the remainder of the work. The hyperparameter optimization algorithms, while efficient for some applications, have issues when used for tracking for a variety of reasons, including their extreme computing weight and the lack of dataset of training for a general fix. For instance, a modern tracker spends a lot of time random grid cv searching 200 times over a validating dataset of 120 films to modify five hyperparameters. Additionally, because tracking can encounter a variety of difficulties that are impractical to address in just 129 sequences, the updated hyperparameters might not be appropriate for all inputs.
 (Kim and Cho, Jun 2019) proposes a methodology for simultaneously locating the activation function and optimization technique in deep learning by focusing on the relationship between forward and backward processes. Given that the deep learning model's search space is relatively broad, the model is searched using genetic programming to locate the ideal point inside the space.  (Shawki et al., Dec 04, 2021) Explained about the standard method for fine-tuning hyperparameters entails manual search, where tests are carried out by a specialist using prior knowledge, experience, and, of course, trial and error. Since this method necessitates a thorough comprehension of the algorithms, it is frequently time-consuming, laborious, and computationally expensive. To discover the best answer, automated search methods are used in the current research field of auto tuning. The approaches for automating the optimization process include Grid Search, Random Search, Bayesian Optimization, and Gradient-based Optimization.
	A generic pipeline for producing the best vector representations of topographical data features is presented in  (Motta et al., Dec 2019a) . Machine learning techniques can then use these vector representations. Each configuration point in this pipeline's complex configuration space defines how features are created and how guesses are learned using those features. This pipeline can be compared to a pricey black-box function. We suggest that while picking learning model parameters, topological vectorization hyperparameters be chosen with the use of cutting-edge Bayesian optimization techniques. With the help of two challenging biological learning problems, we show the value and efficiency of this pipeline and highlight the complex relationships between topological feature creation and learning system hyperparameters.
 (Liu, Wu and Chen, Dec 2020) described the effectiveness of machine learning algorithms depends heavily on hyperparameter optimization (HPO). The computing cost of algorithm assessment is quite high when the method is sophisticated or the datasets is vast, which is a significant barrier for HPO. In this study, we provide an effective hyperparameter tuning technique based on reinforcement learning. A RL agent successively chooses hyperparameters, drastically condensing the search space. The agent is updated using the k-fold cross-validation outcome as a reward signal. We use a prediction model to assess an algorithm using the chosen hyperparameters to hasten the agent's training process.
 
2.5.	Age, Gender, and Ethnicity

 (Hiremath, Patil and Patil, Dec 03, 2021) Proposed that the inevitable stochastic process of ageing affects both people and other living things, and it plays a significant role in face appearance. Human ageing is influenced by both factors, such as variations in softer and bonier facial shapes. The appearance of the face varies greatly depending on age. At various ages, a face takes on a varied appearance. As a result, a technique for determining age and gender from facial features must be developed. Gender identification based on facial traits is widely used in human-computer intercommunication. Additionally, it has many fascinating uses, ranging from online picture searches to automatically determining gender. Researchers have identified gender using a variety of techniques, including 3D facial data, speech, and face picture. Age and gender classification problems still have many unresolved challenges. Despite the advances in vision - based sectors, which continue to produce trying to cut techniques that advance the state-of-the-art, the demands of industry and actual implementation for gender and age estimations on realistic, actual models are still being satisfied.
 (Masood et al., 2018)  Face analysis has been one of the most thoroughly studied study areas in the domains of feature detection and computer vision during the past few decades, as described. Although a person's face can reveal a range of demographic details, including gender, age, and ethnicity, ethnicity nevertheless stands out as a constant and essential characteristic that can't be easily concealed, even in disguise, like age and gender. As a result, classifying people according to age and gender could not only make the task more complex, but would also produce inaccurate results. Because of this, identifying people by their ethnicity is an important feature that can be used in different systems for video surveillance at security checks.
 (Shanthi et al., Jan 20, 2022) Explained age and gender, two important facemask characteristics, are fundamental components of social communication, so estimating them from just one picture is a critical access control, human-computer interface, legal usage, product marketing, and visual examination are only a few examples of tasks in intelligent applications. It is possible to make assumptions about the user's gender and age and utilise this data to create customised products and explanations for each user. By targeting the target audience according to gender and age, it processes a crucial function in marketing for the marketer. 
 
2.6.	Applications and Ethics

(Shanthi et al., Jan 20, 2022) Described age recognition is important in probe by the police and intelligence gathering since it aids in identifying the real criminals and thieves based on his age. They might receive a selected outcome that excludes anyone who has engaged in illegal or other behaviour. The real age and anticipated age would've been roughly the similar if someone gave a skewed assessment of their age after learning the results of an age identification programme. This dependability creates a trustworthiness for numerous other beneficial daily activities. 
Human face pictures reveal a variety of information, including nationality, age, and gender. By automatically detecting faces, recognising gestures and faces, and determining age, gender, and ethnicity, pattern classification and computer vision in the field of machine vision provide an optimum human function. So, it is important to make sure users and consumers are aware if an application incorporates facial recognition technologies. By doing this, you can help others learn about these technologies. It also gives folks who come to or utilise your facilities or technology the option to determine if they want to keep doing so. Technology that recognises or analyses faces points out that it has many applications, identifying missing children, monitoring criminals, making it simpler to use phones and automated teller machines, and assisting robots to communicate with individuals by identifying their personalities and feelings, and in some medical studies, remotely diagnosing or tracking willing participants. However, people should endeavour to prevent the use of technology that may remotely identify or categorise them without their knowledge because it is inherently risky.

### 3.	Human Age, Gender, and Ethnicity Prediction

3.1.	Problem Analysis

The human face can contain information about a person's identity, emotional expression, gender, age, ethnicity, and other personal characteristics. The face's look is significantly impacted by getting older. This is crucial for interpersonal nonverbal communication. Age and gender are two fundamental facial characteristics that are vital to social interactions. Identifying age and sexual orientation from a single face image is consequently a crucial task in machine learning applications including access control, human-computer interaction, police departments, product marketing, and visual surveillance. Because it is a component of social identity and reflects a person's identity, values, and emotions, ethnic identity is also significant. Automatic classification of age, gender, and ethnicity has developed to the point where it is required for long-term use, primarily because old age is linked to online media and social media platforms. However, compared to the enormous performance gains recently shown for the related job of facial recognition, the effectiveness of current solutions based on real-time photos is insufficient.
Here going to find the solutions for the below key objectives
•	To develop a python module to predict Age, Gender and Ethnicity using highly accurate machine learning model
•	To find the best machine learning algorithm for prediction from different Machine learning Algorithms such as KNN, Naive Bayes, CNN and RCNN.
•	To find the best parameter values for each Machine Learning Algorithms and use it for prediction
•	To detect the face from own camera and predict the age, gender, and ethnicity of that face.  
Hyperparameter optimization techniques have been used in many machine learning algorithms to make more accurate predictions, so it is possible to find the best algorithm and their parameter values in the prediction of age, gender, and ethnicity even though many machine learning algorithms have been tried and failed to find age, gender, and ethnicity on numerous occasions.

3.2.	Solution Design

In unrestricted real-life circumstances, such those at train stations, banking, bus stations, and airports, the classification of gender, age, and ethnicity can forecast gender, age, and ethnicity. In human-computer interaction, gender may often be determined based on features of the face. Furthermore, it can be used for a variety of exciting things, including gender auto-detection and internet image searches. Using a range of methods, including facial photos, voice, and 3D face data, researchers have been able to determine a person's gender. As technology advances, it becomes more useful for business and actual solutions to guess age, ethnicity, and gender.
The main goal of the entire project is to develop a Python module to forecasting Gender, Ethnicity, and Age using a highly accurate machine learning model, find the best machine learning algorithm from a variety of algorithms like KNN, Naive Bayes, CNN, and RCNN, and use it for prediction. Another goal is to detect faces from one's own camera and predict the age, gender, and ethnicity of those faces. In order to satisfy all of these needs, a suitable structure was designed.

<img width="695" height="868" alt="image" src="https://github.com/user-attachments/assets/c798279a-3767-4e50-83a5-136cafb68017" />

 Figure 1: Flow Diagram for Classification Model

Figure 1 illustrates how the process was divided into three distinct sections. these three steps are choosing the best model, processing data, and applying the final prediction model. Data loading, characterising, and gathering all the data about each column and its values are done during the data pre-processing step. To view how the picture data appears, process the pixel data, and then display the image arrays. according to the expected execution of the normalisation and standardisation process. Following then, several pre-processing approaches continued depending on the machine learning models, such as data augmentation and data conversion to different dimensions. 
The four separate machine learning models KNN, Naive Bayes, CNN, and RCNN are initialised with a minimum of three distinct hyperparameters and values during the phase of best model selection. Every single model undergoes training and testing using the randomised cv search hyperparameter optimization technique. The best result from each search has been saved in a data frame, which is subsequently converted to a csv file. Finally, csv files are generated for each machine learning model. Finding the optimal machine learning model and its optimum hyperparameters after analysing all the findings. Finally, the best model is validated using the remaining data after training with more than 90% of the data. While training, the most accurate age, gender, and ethnicity prediction model is stored in h5 format. The final stage was conducting real-time prediction using OpenCV and an already-existing saved trained model, with the prediction outcome presented in the OpenCV window. A module is called and executed during the entire process in order to do real-time prediction. It can be used as a package in other situations because it was generated as a module.

3.3.	Machine Learning and Deep Learning Models

3.3.1	K- Nearest Neighbour Algorithm for Classification

Regression and classification problems are the foundation of the KNN algorithm, which has the advantages of being easy to build and having a short learning curve. The process for classifying it is as follows: Decide which sample will be tested, select the K examples under test's K nearest neighbours in the centre of all the training images, and then classify the K specimens under testing in the K Closest neighbours using majority vote. In this way, the K samples that are being tested are classified and identified (Fan et al., 2021). The K-Nearest-Neighbours (KNN) method is indeed a non-parametric classification technique since it makes no assumptions about the fundamental dataset. It is renowned for being simple to use and effective. It is a supervised learning algorithm. To use a labelled training set where the data points are split up into many groups, it is possible to determine the category of the unlabelled data (Taunk et al., May 2019b) .

<img width="245" height="254" alt="image" src="https://github.com/user-attachments/assets/3dc1d067-a780-4105-a24b-c04bc6709bf1" />

 Figure 2: The Distribution of Data points of KNN Model

<img width="294" height="202" alt="image" src="https://github.com/user-attachments/assets/79935e0b-f351-411e-b6f4-83078aef86b1" />

 Figure 3: The first point obtained representative of KNN Model

When utilising Distance measure as our similarity metric, it is clear that numerous data sets that share the same classifier are close to each other in many local locations. The greatest feasible representation of each local region may be provided by the centralized data point di, as shown in Figure 3, along with extra info such as N(p1), the total amount of locations within the local region, and S(p1), the degree to which the the furthest data point inside the particular region resembles p1. If we use those representations as a model to depict the full training dataset, the amount of information values necessary for classification would be significantly reduced. This will make the classifying process more efficient. It naturally follows that if a new data point is included in a representation, it will be classified using that representation's class label. If not, we use each border as a set of data to calculate the range between the new value so each representative's nearest border before categorising the new data point using KNN (Guo, 2021). Given that the KNN model is one that works best for categorization, it is anticipated to perform well in the prediction of age, gender, and ethnicity. This model, which has shown good performance in image classification, can predict multiclassification of age and ethnicity of face image and binary classification of gender with good accuracy.

### Knn Algorithm works on Age, Gender and Ethnicity Classification

A popular classification technique is K-nearest neighbours (KNN). It is frequently employed due to its simple interpretation and quick calculation. In this algorithm, the choice of the parameter k is extremely important. It is necessary to access two parameters on various k values: the training error rate and the validation error rate. The KNN algorithm's text classification domain is very broad. For instance, a system was proposed to achieve good governance and democratic participation by addressing how to classify citizen complaints during the city development process  (Moldagulova and Sulaiman, May 2017) . The categorization of the unlabeled data is determined by a variety of factors. KNN is most frequently used as a classifier. Data is categorised using nearby or adjacent training sets in a specific location. This method is used because it computes quickly and is simple to use. It uses the Euclidean distance to locate its nearest neighbours when working with continuous data (Taunk et al., May 2019b) .

<img width="803" height="403" alt="image" src="https://github.com/user-attachments/assets/d010c121-e938-4ae3-98d7-219bdc3b619e" />

 Figure 4: Age, Gender and Ethnicity Prediction using KNN Model

As shown in the figure above, the image space and the age, gender, and ethnicity data to be predicted are fed into three separate KNN models and trained. Using this train model for prediction. Using pre-partitioned data for training. Similarly, check how well the trained model predicts and see the accuracy of the model used by data for testing. The accuracy scores of all three models of the KNN algorithm are stored into a common data frame. The performance of the KNN algorithm is then evaluated in comparison to other models using this data.

<img width="230" height="190" alt="image" src="https://github.com/user-attachments/assets/bfc3b744-415f-4253-a304-ecf8772515cd" />

 Figure 5: Gender Classification Trained by KNN Model

<img width="207" height="179" alt="image" src="https://github.com/user-attachments/assets/fc23d26c-ebfa-4000-aeec-cb169d8e8a91" />

 Figure 6: Gender Classification Prediction using Knn Model

Figure 5 provides information about the training of the model for KNN gender prediction. Accordingly, a given data is separated into male and female clusters based on the value of each of its features. As Figure 6 shows, if a new datapoint is brought to the surface in Figure 5, the KNN model predicts which cluster it should be classified into. For that, K number of datapoints closest to the new datapoint are found from the surface using Euclidean distance method. It then predicts which cluster most of those datapoints belong to and predicts the class of that cluster as a result.

#### CNN Algorithm works on Age, Gender, and Ethnicity Classification

It is laborious and time-consuming to manually classify every image to compile a sizable, labelled training dataset for age, gender, and ethnicity estimation from social image repositories. This involves access to the participants' frequently personal information. As a result, age, gender, and ethnicity prediction data sets from real-world social photos are currently substantially smaller than the much bigger data sets for image categorization. When machine learning-based approaches are applied to such small image collections, overfitting is a prevalent issue. Deep convolutional neural networks, which have an enormous number of model parameters, make this issue worse. Therefore, it's important to take precautions to avoid overfitting in these situations  (Levi and Hassncer, Jun 2015b) . 

The R-CNN imposes a large computational burden by necessitating its forward traversal through to the CNN model in order to extract features for each item suggestion. The SPPnet and also the Fast R-CNN have both been proposed as remedies for this problem. Instead of feeding it each distorted proposed image region, the SPPnet and Fast R-CNN feed the entire image as input through the CNN exact once. Each proposal can be projected to convolution maps and then retrieved as a fixed temporal feature vector in a manner similar to spatial pyramid pooling. The SPPnet's Fast R-CNN uses the region of interest (RoI) pool layer, which enables edge fine-tuning of an ImageNet network that has previously been trained. It works superior to the original R-CNN because of this. To minimise the computation complexity of proposal creation, the Faster R-CNN was proposed. It contains two modules. In the first module, item proposals are created using a fully convolutional network called the Regional Proposal Network (RPN), which are then input into to the second module. The second module, the Fast R-CNN detector, is utilised to refine the suggestions. The important idea is to employ the same convolutional layers for the RPN and Fast R-CNN detectors up to the completely connected layers. For the purpose of creating and then improving item recommendations, CNN currently only processes an image once. More crucially, the pooling of convolutional layers makes it possible to deploy a quite deep network (like VGG16) to deliver high-quality object recommendations (Huaizu Jiang and Learned-Miller, May 2017) .


#### Faster R-CNN Algorithm works on Age, Gender, and Ethnicity Classification

The imaging of facial expressions is easily influenced by external factors like light, and the obscuration of facial identification by items like glasses or hair will also alter this process. In addition, the tiny variations in facial expressions, such as the picture angle, an eye blink, the closing and opening of the lips, etc., would result in a variety of various performances within the same emotion and make the identification process more challenging. The efficacy of deep learning CNN to take out face identification features can be better through picture pre-processing, which can also effectively reduce the influence of ambient elements like light  (Hua and Tong, Jun 2020) . After the convolutional of a trained network in the RPN, there is a 3 x 3 convolution. This results in the input image's large spatial frame or facilities (for example, 228 228 for VGG16) being transformed into a 1D feature map at a central stride (e.g., 16 for VGG16). Then, two 1 x 1 convolutional layers are created for the classification and regression branches of all geographically windows. The RPN introduces anchors to deal with the various sizes and perspective ratios of things. Each sliding position in the convolutional maps has an anchor, which places it in the middle of each spatial window. A scaling and an image resolution are connected to each anchor. The default option of leads to k = 9 anchors at each position when we use 3 sizes (1282, 2562, and 5122 pixels) and 3 dimensions (1:1, 1:2, and 2:1). According to an anchor, each proposition is parameterized. The number of potential proposals for a map of convolutional features of size W x H is therefore at most WHk  (Huaizu Jiang and Learned-Miller, May 2017) .

3.4.	Hyperparameter Optimization

Using a limited number of subset from the input and target spaces, the machine learning techniques aims to develop a representation of the functional connection between a set of predictor variables and output variables  (A. Singh, N. Thakur, and A. Sharma, 2016) . There are several ways to model Such an ambiguous connection, the majority of such models are very flexible because they have a lot of parameters that can be adjusted to fit the data using a set training technique. In fact, due to overfitting, it is frequently possible to create such a model and create a correct representation of the ambiguous function. Most supervised learning techniques include HPs that limit the model's maximum complexity, such as additional regularisation parameters, to prevent the issue of overfitting  (Motta et al., Dec 2019b) .
	Hyperparameter optimization is a technique that can be used to increase the accuracy score. Factors that can affect the accuracy of this KNN model are that age and ethnicity must be divided into more than five categories, and a larger amount image must be predicted. On a broad scale, Bayesian optimization techniques are effective because they select the following hyperparameters intelligently. The essential concept is to select the subsequent hyperparameters more carefully to use the objective function less frequently. The time spent choosing the following hyperparameters is usually negligible in comparison to the time spent on the objective function. Bayesian approaches can uncover better model configurations than random check in fewer samples by considering hyperparameters that seem more promising from previous findings  (Will Koehrsen, 2018)  . 
	Therefore, using the hyperparameter optimization technique, a good model can be used for prediction by setting the most suitable parameter value that gives the highest accuracy. In order to assess the impact of proportional gain, batch size, and iteration times on face recognition accuracy rate and to determine which method model has an improved training impact of hyper parameter values, the high performing was affirmed whenever the training error was less, the batch size was 32, 64, or 128, and the iterations were between 20 and 100. The results of empirically demonstrating the influence of learning rate, batch size, and iteration periods on the effectiveness of classification detection (Hua and Tong, Jun 2020) . Based on its learning characteristics, CNN optimises its perceptual hash algorithm hyperparameters. A solid notion for the creation of model training methods is also provided by the hyperparameter optimization technique using the deep learning technique convolution feature rebuild visualisation described in this research  (Wang et al., Oct 2020) .

### 4.	Discussion

4.1.	Data Pre-processing and Region Extraction

The goal of a digital image operation is to obtain an improved and clear process of extracting specific information. The output is produced in accordance with the specifications after an input image has been taken, enhanced, or specific features related with the image have been extracted. Since most photos need to be enhanced or simply a specific area of interest needs to be processed further, graphics rendering is a constantly expanding industry and the foundation of many study fields  (Ghildiyal et al., Dec 03, 2020) . 
	Pre-processing, cleansing, and other changes of the dataset will enable more precise machine learning training. For purposes of transformation, cleaning, and pre-processing, pandas is the best Python package. Each machine learning algorithm employs a distinct approach to data pre-processing. The employment of four separate algorithms necessitates the use of pre-processing methods that are appropriate for each algorithm. To accommodate all algorithms, broad structural changes to the data were performed. The dataset utilised in this study was obtained from Kaggle, the world's largest data science community with a wealth of helpful tools and resources. NIPUN ARORA posted this dataset to Kaggle two years ago. The csv-formatted dataset comes with a variety of images as well as details about age, gender, and ethnicity. After data preparation and cleaning, the csv file is generated using the UTA dataset. The face dataset from the University of Tennessee, Knoxville was used to create this csv file. 
	This information is broken down into five columns: age, gender, ethnicity, image name, and pixels. Here, the primary columns that must be used for classification are the pixel, age, gender, and ethnicity. The image name field is not crucial for the classification. Therefore, before beginning to train the machine learning system, that column can easily be deleted. For the convenience of the pre-processing approaches, it is recommended that all column values be thoroughly checked before pre-processing. Continuous values make up the age column, which is being converted into various age groups as part of the pre-processing for the development of a classification model. The value counts for the age, gender, and ethnicity columns are shown in table 1.
	
<img width="726" height="318" alt="image" src="https://github.com/user-attachments/assets/b4372c86-5972-40b7-85a2-a61ac9549d12" />

The age column has seven different age ranges, with the 21–30 age range having the highest overall count. There are two categories in the gender column, and the number of each category is roughly equivalent. From this, the accuracy of the predictions for both gender categories will be around the same. The format of the pixel column was object datatype. For the building of the image prediction model, that column has been modified to the picture array format. These are the main methods used for all machine learning models when pre-processing data. Images have been transformed into a one-dimensional array for the KNN and Naive Bayes machine learning models. Since the knn and naïve bayes models favour employing a single two-dimensional array for both training and also testing. The picture array is being converted to a 48 x 48-dimensional array for the convolutional neural network model. The image was then processed in more than one format using the ImageDataGenerator function to increase the model's prediction accuracy. Pre-processing for the RCNN model differs from other pre-processing methods in this picture data in a significant way. The image array and the box's coordinate points, which are a component of the original picture, are used in the RCNN model and the Faster R-CNN model for conducting model training. In this instance of facial prediction, each area of the face and its four corner points are detected in each image and saved in a different data frame. The Faster R-CNN model was then trained and tested using this data frame.

4.2.	Training, Validation and Testing Dataset

Table 1 shows that certain categories of age, gender, and ethnicity are represented, creating an ustable data. For instance, only about 46% of the photos of English faces were classified as white, with the remaining 54% falling into another of the finer-grained ethnicity groups. A classifier with an accuracy of 70% tends to always yield white to be the most likely class when learned on the unbalanced dataset. This exhibits the operation of a simple algorithm that consistently produces the same result. A roughly similar number of photos from each category were chosen for sampling, resulting in balanced validation and training datasets. Each category's remaining photographs are used for evaluation. When training the CNN and Faster R-CNN it's critical to make sure that the distribution of the classes is uniform; otherwise, weight updates would deviate from the assumptions of uniform prior distribution.
	Divide the data into a training and testing dataset to track and manage overfitting. The performance of the validation set was assessed following each training epoch. how many samples from each demographic group were used for the investigations' training, validation, and testing phases. I set a cap of 80% on the number of pictures in each category when training the age, gender, and ethnicity models. The remaining 20% of the data were used for testing. To boost the quantity of training images, I employed data augmentation. Mirroring the image results in data augmentation. As a result, the quantity of photos used for training is doubled. To provide more reliable data for training and testing, certain normalisation approaches were also applied. I utilised a minimum of two parameters for hyperparameter optimization, with three alternative values for each. The prediction model becomes more precise as a result.
	
### Result

Using four different machine learning algorithms, three different prediction techniques, and their hyperparameters, this research was able to develop the best real-time model. The results can be utilised to conduct a comparative analysis of the four different algorithms and their hyperparameters based on their accuracy scores.
Prediction	Model	Best Parameter	Accuracy

<img width="927" height="529" alt="image" src="https://github.com/user-attachments/assets/4c880acc-7e1e-44ab-8d42-739187163ab3" />

 Table 2: Models Accuracy Comparison Table

Table 2 displays the comparison results and hyperparameters for the four distinct machine learning and deep learning methods. When analysing the KNN algorithm, it predicts age and gender with an accuracy of over 50%, but it predicts ethnicity with an accuracy that is too low. When the Naive Bayes method is used, it provides the lowest accuracy in all predictions when compared to all other algorithms. The naive Bayes algorithm need not be the worst method for predictions based just on this scenario. It is possible for an algorithm to provide less accuracy owing to a variety of factors, such as the failure of a pre-processing approach for a certain algorithm, inconsistent data, etc. 
	It is abundantly evident from the chart that the convolutional neural network's accuracy score provides the greatest score in that. The model provides forecasts that are more than 80% correct. Based on this investigation, the best hyperparameter values for the CNN model may be understood. Since two of three different prediction models are offering excellent accuracy with this optimizer and dropout value, the Adam optimizer may be used as the best optimizer in this situation, and 0.2 is the optimum number for dropout in any circumstance. Most scientists and developers use Adam optimizer while performing image prediction using the CNN model. We can deduct from this research why practically all researchers choose the Adam optimizer for their CNN model. However, based solely on the input data, we can also deduce from this finding that the number of units can be any appropriate amount for high accuracy prediction.
	Age, gender, and ethnicity predictions with faster RCNN yield more than 50% accuracy; this is unquestionably a good result given that the image data was not initially in a format that allowed for Faster RCNN prediction. Several pre-processing techniques were employed on the data before the model was applied to get the forecast. Object detection approaches mostly use faster RCNN. In terms of face categorization techniques, it is rarely used. This prediction result allows us to determine that, if we utilise a large enough image dataset, faster RCNN algorithms can effectively be used for face identification techniques.
 
<img width="678" height="282" alt="image" src="https://github.com/user-attachments/assets/7149cfbd-cc4c-43ab-bcd6-9bfe53ecf856" />


The real-time output of the final prediction model using the CNN model is shown in figure 11. For the real-time prediction, the haar cascade approach and the OpenCV Python module were utilised. The image subtraction morphological technique is used by Haar cascades to identify faces. This involves taking and storing many photos of the same subject in a database. When calculating the influence of each colour, all the pixels in the white and black regions are removed from one another. Each image in the cascade is subjected to this kind of subtraction, although not every image will produce the most accurate findings. There are numerous mistakes in many of the photographs. The photograph with the fewest mistakes is chosen. Weak classifier is the result of adding together the results from all the photos. As a result of adding together all the weak classifiers, a powerful classifier is created  (Opencv et al., 2021b) . The CNN model with the best hyperparameter settings, greatest accuracy, and all training data is stored in h5 format. when the camera's faces are recognised by the haar cascade face detector function. The face picture array will then keep transmitting data to the trained models that have been loaded. Using openCV functions on the face region, the prediction results are sent back to the main function, where they are displayed in a real-time camera release window. The prediction results are 100% accurate for real-time prediction, although the trained CNN model accuracy was only 80% above.

4.4.	Evolution

The ability to forecast demographic data automatically from unrestricted facial photos using CNNs has gained popularity in recent years. Fewer articles have concentrated on determining ethnicity from face photos; instead, most papers released in this specialised field of study have mostly concentrate on predicting both gender and age. Age categorization methods are thoroughly reviewed in the literature, and gender classification techniques are discussed  (Srinivas et al., May 2017) . A long time ago, the issue of automated age extraction of attributes came to light. Early age classification involved calculating the ratio between several facial traits such the nose, eyes, lips, and chin. So, order to determine age using conventional methods, their ratios are derived after localising and estimating their sizes and distances. A model was recently presented to depict the ageing of individuals under the age of 18, however it is ineffective, and the images on social media differ. There are further techniques for age prediction. However, it necessitates precise alignment and front-facing images, thus that proposal also falls short of the requirements. Therefore, these strategies only provide experimental results for small data sets. Therefore, using such approaches on independent datasets is inappropriate. (Shanthi et al., Jan 20, 2022) 
	Facial recognition technology has advanced significantly during the past 20 years. In the modern era, identity information can be checked automatically for managing building access as well as for cryptographically secure, tracking, and security requirements. The runtime environment for these devices is often controlled, and detection techniques may modify environmental constraints to obtain high recognition accuracy. The next phase of technology for facial recognition will, however, be widely used in intelligent workplaces where machines and computers act more as helpful assistants  (Khan et al., Oct 2019b) .
	
4.5.	Challenges, Limitations, and Improvements

Research on facial recognition is frequent these days. My initial aim and purpose for this research was to create a new throughput. There have been numerous studies conducted with the highest degree of precision. However, there were also some problems when the prediction was made in real time. The goal of this research was to make an accurate real-time prediction. Several significant issues exist in the facial recognition sector. The problem of planning the image before using the tool is one. So that a picture may be recognised by one or two classifiers and trained with such a person, for instance, it is one of the abilities to determine if the image is of a man or a woman. When numerous spaces have spectrum-scale individuals in one region, consistency in classification might be achieved. It turns out that this is a collection of oddities for both men and women  (Khan et al., Oct 2019a) .
	There are a lot of facial data available but selecting the most useful data is one of the most crucial aspects of the research. that would be difficult for a researcher to select the right data. I selected a data set for this study that includes all age, gender, and ethnicity classifications. Identification of age, gender, and ethnicity subgroups is the aim of this study. I obtained the age as a continuous value from this data. I developed new age categorization groups based on the data to carry out the classification. How I created the age group and made the prediction was crucial. The most closely related ages and the most repeated ages are kept together in one group based on the age data. This method was selected to extract age groupings from the data. 
	For a predictive analysis, data pre-processing is crucial since an effective pre-processing method will ensure that the forecast is accurate. The problem in one stage was the pre-processing of the data for a speedier RCNN. Pre-processing for the RCNN model in this image data is significantly different from other pre-processing techniques. The Faster R-CNN model and the RCNN model both use the image array and the box's coordinate points, which are a part of the original image, for model training. Each area of the face and its four corner points are identified in each image and saved in a distinct data frame in this example of facial prediction. Then, using this data frame, the Faster R-CNN model was trained and evaluated.
	
### 5.	Summary and Conclusion

In this study, an accurate Python module to predict age, gender, and ethnicity was processed using a machine learning algorithm. The accuracy of various machine learning algorithms and their parameter values were compared and analysed, and the disadvantages and benefits of each machine learning algorithm were then determined. The importance of a parameter value in a machine learning method was also determined. A large number of applications be using this technique since the human faces are thought to be an especially rich collection of information, making face recognition one of the most exciting jobs in pattern recognition in recent years. Gender and age are visual characteristics that can be highly helpful for a variety of applications. For instance, an automatic system for predicting gender and age is used to profile clients who really are interested in a specific product as well as for target advertising. Age and classification techniques have been investigated for a long time (Benkaddour, Lahlali and Trabelsi, Feb 09, 2021b)  . 
	According to this study, the CNN model provides a more accurate prediction of age, gender, and ethnicity. For each prediction model used in this prediction, the accuracy rate is greater than 80%. The accuracy was increased here by using the hyperparameter optimization technique. It doesn't provide greater accuracy than the prior works when compared, nevertheless. It demonstrates that improving hyperparameters alone does not significantly alter the accuracy of face detection models. However, the RCNN model provides predictions with greater than 50% accuracy. Given that the image data wasn't initially in a format that allowed for Faster RCNN prediction, this is clearly a positive outcome. Before the model was used to generate the forecast, a number of pre-processing procedures were applied to the data. It is rarely employed in face categorization methods. This prediction result enables us to establish that quicker RCNN algorithms can be used for face identification methods provided we make use of a sizable image dataset. I advise using new datasets in the future, and pre-processing techniques can be changed to produce results more effectively. Utilizing the pretrained VGG model with CNN or integrating other models with CNN can increase accuracy. It is also possible to increase accuracy by enhancing the quicker RCNN model that is already in use.
